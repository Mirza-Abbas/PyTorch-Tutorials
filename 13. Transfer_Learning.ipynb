{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["x3Npb3_goLAb","vE-xt-yMbUpb","XghadFnJbXlr","MUzk9z13n1ia","iTXOr3ZZbdCL","OLcFZCPlbiK1","Xb2HK1p40UOP","K2SSEN1j0XF5"],"authorship_tag":"ABX9TyPT5JVYwrziz0iAOZVdcm+q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Transfer Learning"],"metadata":{"id":"x3Npb3_goLAb"}},{"cell_type":"markdown","source":["- Using ResNet18 CNN\n","- The network consists of 18 layers\n","- Classifies images into 1,000 object categories\n","- We only want to detect bees and ants"],"metadata":{"id":"cfGUS2uwt9Qr"}},{"cell_type":"markdown","source":["#Import Libraries:"],"metadata":{"id":"vE-xt-yMbUpb"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"nvqbhwMolu-p","executionInfo":{"status":"ok","timestamp":1735731067396,"user_tz":-300,"elapsed":517,"user":{"displayName":"Abbas Mirza","userId":"04098176250439025995"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","import numpy as np\n","import torchvision\n","from torchvision import datasets, models, transforms\n","import matplotlib.pyplot as plt\n","import time\n","import os\n","import copy\n","import requests\n","import zipfile"]},{"cell_type":"markdown","source":["#Device Configuration:"],"metadata":{"id":"XghadFnJbXlr"}},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"id":"auDOA4bPuk6H","executionInfo":{"status":"ok","timestamp":1735731086491,"user_tz":-300,"elapsed":759,"user":{"displayName":"Abbas Mirza","userId":"04098176250439025995"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["#Download Dataset:"],"metadata":{"id":"MUzk9z13n1ia"}},{"cell_type":"code","source":["# dataset url\n","url = \"https://download.pytorch.org/tutorial/hymenoptera_data.zip\""],"metadata":{"id":"DU-hVBexAzWt","executionInfo":{"status":"ok","timestamp":1735731090348,"user_tz":-300,"elapsed":919,"user":{"displayName":"Abbas Mirza","userId":"04098176250439025995"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# directory path to save file\n","data_dir = \"./\"\n","os.makedirs(data_dir, exist_ok=True)"],"metadata":{"id":"4O2lWhKsA1rz","executionInfo":{"status":"ok","timestamp":1735731092614,"user_tz":-300,"elapsed":3,"user":{"displayName":"Abbas Mirza","userId":"04098176250439025995"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# file path to save the ZIP file\n","zip_path = os.path.join(data_dir, \"data.zip\")"],"metadata":{"id":"CSICc9hVA_-r","executionInfo":{"status":"ok","timestamp":1735731094583,"user_tz":-300,"elapsed":5,"user":{"displayName":"Abbas Mirza","userId":"04098176250439025995"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Download file\n","print(\"Downloading file...\")\n","response = requests.get(url)\n","\n","with open(zip_path, \"wb\") as file:\n","    file.write(response.content)\n","print(\"Download complete.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gZ_82XDyBTqs","executionInfo":{"status":"ok","timestamp":1735731099748,"user_tz":-300,"elapsed":2030,"user":{"displayName":"Abbas Mirza","userId":"04098176250439025995"}},"outputId":"f39cc14f-c17e-4e72-8b6b-4ce0d179907c"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading file...\n","Download complete.\n"]}]},{"cell_type":"code","source":["# Extract the ZIP file\n","print(\"Extracting files...\")\n","with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n","    zip_ref.extractall(data_dir)\n","print(\"Extraction complete.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WOMqAOBIBdZK","executionInfo":{"status":"ok","timestamp":1735731106801,"user_tz":-300,"elapsed":1243,"user":{"displayName":"Abbas Mirza","userId":"04098176250439025995"}},"outputId":"2db7f30d-0e67-432c-b4df-253ec5f1d00d"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Extracting files...\n","Extraction complete.\n"]}]},{"cell_type":"markdown","source":["#Load Dataset:"],"metadata":{"id":"iTXOr3ZZbdCL"}},{"cell_type":"code","source":["mean = np.array([0.485, 0.456, 0.406])\n","std = np.array([0.229, 0.224, 0.225])"],"metadata":{"id":"L4sm_znOus6V","executionInfo":{"status":"ok","timestamp":1735731122804,"user_tz":-300,"elapsed":532,"user":{"displayName":"Abbas Mirza","userId":"04098176250439025995"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["data_transforms = {\n","    'train': transforms.Compose([\n","        transforms.RandomResizedCrop(224),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean, std)\n","    ]),\n","    'val': transforms.Compose([\n","        transforms.Resize(256),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean, std)\n","    ]),\n","}"],"metadata":{"id":"nZAx2q0zu_z4","executionInfo":{"status":"ok","timestamp":1735731124925,"user_tz":-300,"elapsed":520,"user":{"displayName":"Abbas Mirza","userId":"04098176250439025995"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["#import data\n","data_dir = './hymenoptera_data' #dataset path\n","sets = ['train', 'val']\n","image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n","                                          data_transforms[x])\n","                  for x in ['train', 'val']}\n","\n","dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n","                                             shuffle=True, num_workers=4)\n","              for x in ['train', 'val']}\n","\n","dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n","class_names = image_datasets['train'].classes\n","print(class_names)"],"metadata":{"id":"GIN78UJfvTK7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735731137755,"user_tz":-300,"elapsed":739,"user":{"displayName":"Abbas Mirza","userId":"04098176250439025995"}},"outputId":"8b8f0104-e889-484a-b1cd-16227851c61b"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["['ants', 'bees']\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","source":["#Training Implementation:"],"metadata":{"id":"OLcFZCPlbiK1"}},{"cell_type":"code","source":["#Training:\n","def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n","    since = time.time()\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","        print('-' * 10)\n","\n","        # Each epoch has a training and validation phase\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()  # Set model to training mode\n","            else:\n","                model.eval()   # Set model to evaluate mode\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            # Iterate over data.\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                # forward\n","                # track history if only in train\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    outputs = model(inputs)\n","                    _, preds = torch.max(outputs, 1)\n","                    loss = criterion(outputs, labels)\n","\n","                    # backward + optimize only if in training phase\n","                    if phase == 'train':\n","                        optimizer.zero_grad()\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                # statistics\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","\n","            if phase == 'train':\n","                scheduler.step()\n","\n","            epoch_loss = running_loss / dataset_sizes[phase]\n","            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n","\n","            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n","                phase, epoch_loss, epoch_acc))\n","\n","            # deep copy the model\n","            if phase == 'val' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","\n","        print()\n","\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(\n","        time_elapsed // 60, time_elapsed % 60))\n","    print('Best val Acc: {:4f}'.format(best_acc))\n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","    return model"],"metadata":{"id":"HDUzoVv0yfD9","executionInfo":{"status":"ok","timestamp":1735731146409,"user_tz":-300,"elapsed":925,"user":{"displayName":"Abbas Mirza","userId":"04098176250439025995"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["#Fine tuning:"],"metadata":{"id":"Xb2HK1p40UOP"}},{"cell_type":"code","source":["#importing pre-trained model:\n","model = models.resnet18(pretrained=True)"],"metadata":{"id":"OaSAO5YqyUyn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735731154706,"user_tz":-300,"elapsed":1342,"user":{"displayName":"Abbas Mirza","userId":"04098176250439025995"}},"outputId":"6ea35e65-bd21-4d99-a81a-76985d9a3e68"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","100%|██████████| 44.7M/44.7M [00:00<00:00, 164MB/s]\n"]}]},{"cell_type":"code","source":["#modifying the model\n","num_ftrs = model.fc.in_features #no. of input features for last layer\n","\n","model.fc = nn.Linear(num_ftrs, 2) #replacing last layer\n","model.to(device)"],"metadata":{"id":"9fH1YNehynjV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735731160979,"user_tz":-300,"elapsed":615,"user":{"displayName":"Abbas Mirza","userId":"04098176250439025995"}},"outputId":"6646f14a-e954-4c79-d5ce-0fd81050e683"},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["#loss & optimizer:\n","criterion = nn.CrossEntropyLoss()\n","\n","optimizer = optim.SGD(model.parameters(), lr=0.001)"],"metadata":{"id":"vQyPZ-O7zAu3","executionInfo":{"status":"ok","timestamp":1735731187522,"user_tz":-300,"elapsed":3,"user":{"displayName":"Abbas Mirza","userId":"04098176250439025995"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["#scheduler: (for updating learning rate)\n","\n","step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1) #every 7 epochs, lr multiplies by 0.1"],"metadata":{"id":"ePHgt5dwzND4","executionInfo":{"status":"ok","timestamp":1735731192869,"user_tz":-300,"elapsed":813,"user":{"displayName":"Abbas Mirza","userId":"04098176250439025995"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["model = train_model(model, criterion, optimizer, step_lr_scheduler, num_epochs=2)"],"metadata":{"id":"1KFW6bQpzlVm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735731368344,"user_tz":-300,"elapsed":170923,"user":{"displayName":"Abbas Mirza","userId":"04098176250439025995"}},"outputId":"c873f2c6-3bd1-4a0e-fb5b-aafbcfbf17be"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0/1\n","----------\n","train Loss: 0.6687 Acc: 0.5943\n","val Loss: 0.5277 Acc: 0.7582\n","\n","Epoch 1/1\n","----------\n","train Loss: 0.5471 Acc: 0.7172\n","val Loss: 0.3539 Acc: 0.8954\n","\n","Training complete in 2m 50s\n","Best val Acc: 0.895425\n"]}]},{"cell_type":"markdown","source":["#Freezing Layers:"],"metadata":{"id":"K2SSEN1j0XF5"}},{"cell_type":"code","source":["#importing pre-trained model:\n","model = models.resnet18(pretrained=True)"],"metadata":{"id":"gYujJ2em0b5a","executionInfo":{"status":"ok","timestamp":1735731387174,"user_tz":-300,"elapsed":474,"user":{"displayName":"Abbas Mirza","userId":"04098176250439025995"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["#loop over model parameters\n","for param in model.parameters():\n","  param.requires_grad = False #freezers all layers in the beginning"],"metadata":{"id":"DLhETOKT0gsF","executionInfo":{"status":"ok","timestamp":1735731389693,"user_tz":-300,"elapsed":7,"user":{"displayName":"Abbas Mirza","userId":"04098176250439025995"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["#modifying the model\n","num_ftrs = model.fc.in_features #no. of input features for last layer\n","\n","model.fc = nn.Linear(num_ftrs, 2) #creating new last layer\n","model.to(device)"],"metadata":{"id":"IGEIBfR50b5b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735731393706,"user_tz":-300,"elapsed":833,"user":{"displayName":"Abbas Mirza","userId":"04098176250439025995"}},"outputId":"a93d9de5-3dc5-48f0-8149-31e66ce51151"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=2, bias=True)\n",")"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["#loss & optimizer:\n","criterion == nn.CrossEntropyLoss()\n","\n","optimizer = optim.SGD(model.parameters(), lr=0.001)"],"metadata":{"id":"UxyNbjqV0b5b","executionInfo":{"status":"ok","timestamp":1735731398584,"user_tz":-300,"elapsed":489,"user":{"displayName":"Abbas Mirza","userId":"04098176250439025995"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["#scheduler: (for updating learning rate)\n","\n","step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1) #every 7 epochs, lr multiplies by 0.1"],"metadata":{"id":"jlbdwI2A0b5c","executionInfo":{"status":"ok","timestamp":1735731411648,"user_tz":-300,"elapsed":4,"user":{"displayName":"Abbas Mirza","userId":"04098176250439025995"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["model = train_model(model, criterion, optimizer, step_lr_scheduler, num_epochs=2)"],"metadata":{"id":"kTl2_1080b5c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735731498281,"user_tz":-300,"elapsed":81416,"user":{"displayName":"Abbas Mirza","userId":"04098176250439025995"}},"outputId":"99745e6c-38c6-4052-af53-f3a0f815c95f"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0/1\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 0.7233 Acc: 0.5451\n","val Loss: 0.6325 Acc: 0.6405\n","\n","Epoch 1/1\n","----------\n","train Loss: 0.6305 Acc: 0.6107\n","val Loss: 0.4810 Acc: 0.7974\n","\n","Training complete in 1m 21s\n","Best val Acc: 0.797386\n"]}]}]}