{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["8ZY5fk7MveQV","sWZLXhtEwMxG","YGj4__eNxfdE","uUXrwBZtyiS7","S9qXFadq1hV6","QCTgguWU507-","VMXGf2497Zkv","35b9sqik7dCl","gDw_Ox757fwJ"],"authorship_tag":"ABX9TyOJLSUQrRJEv1LpVkv9A7Zm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Saving and Loading Model"],"metadata":{"id":"8ZY5fk7MveQV"}},{"cell_type":"markdown","source":["##Importing Libraries:"],"metadata":{"id":"sWZLXhtEwMxG"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn"],"metadata":{"id":"N8olgdsNvhVt","executionInfo":{"status":"ok","timestamp":1735233027400,"user_tz":-300,"elapsed":11160,"user":{"displayName":"Abbas Mirza","userId":"04098176250439025995"}}},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":["##Option 1 - Lazy Method:"],"metadata":{"id":"YGj4__eNxfdE"}},{"cell_type":"markdown","source":["- torch.save() can use tensors, models or any dictionary as parameter for saving\n","\n","- python uses pickle module to serialize the objects and saves them\n","\n","- the result is serialized and not human readable\n","\n","- to load model: model = torch.load(PATH)\n"],"metadata":{"id":"Ijr-k2K3zqPU"}},{"cell_type":"code","source":["class Model(nn.Module):\n","\n","  def __init__(self, n_input_features):\n","    super(Model, self).__init__()\n","    self.linear = nn.Linear(n_input_features, 1)\n","\n","  def forward(self, x):\n","    y_pred = torch.sigmoid(self.Linear(x))\n","    return y_pred"],"metadata":{"id":"c16Em3Lbxgn1","executionInfo":{"status":"ok","timestamp":1735233051089,"user_tz":-300,"elapsed":337,"user":{"displayName":"Abbas Mirza","userId":"04098176250439025995"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["model = Model(6)\n","\n","#model training...."],"metadata":{"id":"lSwEU05bxvxh","executionInfo":{"status":"ok","timestamp":1735233051403,"user_tz":-300,"elapsed":3,"user":{"displayName":"Abbas Mirza","userId":"04098176250439025995"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["#inspecting model parameters\n","print(\"Model Parameters:\")\n","for param in model.parameters(): #weights and bias\n","  print(param)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZVyl8ReRzUvP","executionInfo":{"status":"ok","timestamp":1735233051896,"user_tz":-300,"elapsed":495,"user":{"displayName":"Abbas Mirza","userId":"04098176250439025995"}},"outputId":"7650f573-1f41-4c91-a45b-2a7b48b96da5"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Model Parameters:\n","Parameter containing:\n","tensor([[ 0.1045, -0.1647, -0.2671,  0.0191, -0.0509,  0.2351]],\n","       requires_grad=True)\n","Parameter containing:\n","tensor([-0.0604], requires_grad=True)\n"]}]},{"cell_type":"code","source":["FILE = \"model.pth\" #filepath variable\n","#.pth is short for pytorch"],"metadata":{"id":"_tum7Olsx1T_","executionInfo":{"status":"ok","timestamp":1735233051896,"user_tz":-300,"elapsed":9,"user":{"displayName":"Abbas Mirza","userId":"04098176250439025995"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["torch.save(model, FILE)"],"metadata":{"id":"nz8RKAqcyDc8","executionInfo":{"status":"ok","timestamp":1735233051896,"user_tz":-300,"elapsed":8,"user":{"displayName":"Abbas Mirza","userId":"04098176250439025995"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["#load model\n","model = torch.load(FILE)\n","model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gods8ZTLyQ5Q","executionInfo":{"status":"ok","timestamp":1735233051897,"user_tz":-300,"elapsed":8,"user":{"displayName":"Abbas Mirza","userId":"04098176250439025995"}},"outputId":"af416411-34bb-4225-bf26-59e78fbdeb2a"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-7-c36fd118b5d2>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model = torch.load(FILE)\n"]},{"output_type":"execute_result","data":{"text/plain":["Model(\n","  (linear): Linear(in_features=6, out_features=1, bias=True)\n",")"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["#inspecting loaded model parameters\n","print(\"Loaded Model Parameters:\")\n","for param in model.parameters(): #weights and bias\n","  print(param)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aTQoBE7qyXdz","executionInfo":{"status":"ok","timestamp":1735233051897,"user_tz":-300,"elapsed":5,"user":{"displayName":"Abbas Mirza","userId":"04098176250439025995"}},"outputId":"d61b6a79-47da-4852-b3d1-1fde20d42b29"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded Model Parameters:\n","Parameter containing:\n","tensor([[ 0.1045, -0.1647, -0.2671,  0.0191, -0.0509,  0.2351]],\n","       requires_grad=True)\n","Parameter containing:\n","tensor([-0.0604], requires_grad=True)\n"]}]},{"cell_type":"markdown","source":["##Option 2 - State Dict Method: (Recommended)"],"metadata":{"id":"uUXrwBZtyiS7"}},{"cell_type":"markdown","source":["- Recommended method for saving the model and using it later for inference\n","\n","- only saves parameters of the model\n","\n","- torch.save(model.state_dict(), PATH)\n","\n","- To load model: model.load_state_dict(torch.load(PATH))"],"metadata":{"id":"o8gxmR5M0GXp"}},{"cell_type":"code","source":["class Model(nn.Module):\n","\n","  def __init__(self, n_input_features):\n","    super(Model, self).__init__()\n","    self.linear = nn.Linear(n_input_features, 1)\n","\n","  def forward(self, x):\n","    y_pred = torch.sigmoid(self.Linear(x))\n","    return y_pred"],"metadata":{"id":"J2LizRhQy0CX","executionInfo":{"status":"ok","timestamp":1735233140427,"user_tz":-300,"elapsed":395,"user":{"displayName":"Abbas Mirza","userId":"04098176250439025995"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["model = Model(6)\n","\n","#model training...."],"metadata":{"id":"Og7nL_4ky0CY","executionInfo":{"status":"ok","timestamp":1735233140774,"user_tz":-300,"elapsed":23,"user":{"displayName":"Abbas Mirza","userId":"04098176250439025995"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["#inspecting model parameters\n","print(\"Model Parameters:\")\n","for param in model.parameters(): #weights and bias\n","  print(param)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RmF3Bf2pzQif","executionInfo":{"status":"ok","timestamp":1735233140774,"user_tz":-300,"elapsed":23,"user":{"displayName":"Abbas Mirza","userId":"04098176250439025995"}},"outputId":"be93c37f-8c4b-4df4-a09c-88f7019fae7a"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Model Parameters:\n","Parameter containing:\n","tensor([[ 0.3293,  0.2730,  0.2050,  0.0291, -0.3129, -0.2614]],\n","       requires_grad=True)\n","Parameter containing:\n","tensor([0.0447], requires_grad=True)\n"]}]},{"cell_type":"code","source":["FILE = \"model.pth\" #filepath variable\n","#.pth is short for pytorch"],"metadata":{"id":"8STlcOkly0CY","executionInfo":{"status":"ok","timestamp":1735233140774,"user_tz":-300,"elapsed":21,"user":{"displayName":"Abbas Mirza","userId":"04098176250439025995"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["#save model parameters\n","\n","torch.save(model.state_dict(), FILE)"],"metadata":{"id":"HJOBWFv7yoNK","executionInfo":{"status":"ok","timestamp":1735233140774,"user_tz":-300,"elapsed":21,"user":{"displayName":"Abbas Mirza","userId":"04098176250439025995"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["print(\"Model State Dict: \", model.state_dict())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HsZC-mmP1LOv","executionInfo":{"status":"ok","timestamp":1735233140774,"user_tz":-300,"elapsed":20,"user":{"displayName":"Abbas Mirza","userId":"04098176250439025995"}},"outputId":"7fda49c9-ee0d-496f-92c9-047c1a0e33e2"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Model State Dict:  OrderedDict([('linear.weight', tensor([[ 0.3293,  0.2730,  0.2050,  0.0291, -0.3129, -0.2614]])), ('linear.bias', tensor([0.0447]))])\n"]}]},{"cell_type":"code","source":["#load model parameters\n","\n","loaded_model = Model(6) #initializing model\n","loaded_model.load_state_dict(torch.load(FILE))\n","loaded_model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-DDri-vpy9er","executionInfo":{"status":"ok","timestamp":1735233197064,"user_tz":-300,"elapsed":10,"user":{"displayName":"Abbas Mirza","userId":"04098176250439025995"}},"outputId":"51dc438b-f2c4-46e2-a49c-3c4a502affb4"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-16-82d44158b2c8>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  loaded_model.load_state_dict(torch.load(FILE))\n"]},{"output_type":"execute_result","data":{"text/plain":["Model(\n","  (linear): Linear(in_features=6, out_features=1, bias=True)\n",")"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["#inspecting loaded model parameters\n","print(\"Loaded Model Parameters:\")\n","for param in model.parameters(): #weights and bias\n","  print(param)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ml5tsWPIzPZV","executionInfo":{"status":"ok","timestamp":1735233200656,"user_tz":-300,"elapsed":414,"user":{"displayName":"Abbas Mirza","userId":"04098176250439025995"}},"outputId":"e76d9503-9e46-432e-f1d9-eb1ffc2d7222"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded Model Parameters:\n","Parameter containing:\n","tensor([[ 0.3293,  0.2730,  0.2050,  0.0291, -0.3129, -0.2614]],\n","       requires_grad=True)\n","Parameter containing:\n","tensor([0.0447], requires_grad=True)\n"]}]},{"cell_type":"code","source":["print(\"Loaded Model State Dict: \", loaded_model.state_dict())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8X3rilhh1UMt","executionInfo":{"status":"ok","timestamp":1735233224447,"user_tz":-300,"elapsed":318,"user":{"displayName":"Abbas Mirza","userId":"04098176250439025995"}},"outputId":"d0258b73-8011-4b15-baec-b016acb5143c"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded Model State Dict:  OrderedDict([('linear.weight', tensor([[ 0.3293,  0.2730,  0.2050,  0.0291, -0.3129, -0.2614]])), ('linear.bias', tensor([0.0447]))])\n"]}]},{"cell_type":"markdown","source":["##Saving Checkpoint During Training:"],"metadata":{"id":"S9qXFadq1hV6"}},{"cell_type":"code","source":["class Model(nn.Module):\n","\n","  def __init__(self, n_input_features):\n","    super(Model, self).__init__()\n","    self.linear = nn.Linear(n_input_features, 1)\n","\n","  def forward(self, x):\n","    y_pred = torch.sigmoid(self.Linear(x))\n","    return y_pred"],"metadata":{"id":"KUfC7a3Y1mcL","executionInfo":{"status":"ok","timestamp":1735233244573,"user_tz":-300,"elapsed":317,"user":{"displayName":"Abbas Mirza","userId":"04098176250439025995"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["model = Model(6)\n","\n","#model training...."],"metadata":{"id":"RO-MnGVG1mcL","executionInfo":{"status":"ok","timestamp":1735233244878,"user_tz":-300,"elapsed":3,"user":{"displayName":"Abbas Mirza","userId":"04098176250439025995"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["learning_rate = 0.01\n","\n","optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"],"metadata":{"id":"4Kw1-QL638Uc","executionInfo":{"status":"ok","timestamp":1735233250357,"user_tz":-300,"elapsed":5482,"user":{"displayName":"Abbas Mirza","userId":"04098176250439025995"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["print(\"Optimizer State Dict: \",optimizer.state_dict())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yDPLX3qW4CHB","executionInfo":{"status":"ok","timestamp":1735233250357,"user_tz":-300,"elapsed":20,"user":{"displayName":"Abbas Mirza","userId":"04098176250439025995"}},"outputId":"0e73b236-056e-4a8f-8e7e-0b3a2c890df8"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Optimizer State Dict:  {'state': {}, 'param_groups': [{'lr': 0.01, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'fused': None, 'params': [0, 1]}]}\n"]}]},{"cell_type":"code","source":["#creating a dictionary:\n","checkpoint = {\n","    \"epoch\": 90,\n","    \"model_state\": model.state_dict(),\n","    \"optim_state\": optimizer.state_dict()\n","}"],"metadata":{"id":"hFw4F1Wt4P-q","executionInfo":{"status":"ok","timestamp":1735233250357,"user_tz":-300,"elapsed":18,"user":{"displayName":"Abbas Mirza","userId":"04098176250439025995"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["#saving checkpoint\n","torch.save(checkpoint, \"checkpoint1.pth\")"],"metadata":{"id":"GdSHI7KU4c2K","executionInfo":{"status":"ok","timestamp":1735233250358,"user_tz":-300,"elapsed":18,"user":{"displayName":"Abbas Mirza","userId":"04098176250439025995"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["#loading checkpoint\n","loaded_checkpoint = torch.load(\"checkpoint1.pth\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XSCh6_UV4v5L","executionInfo":{"status":"ok","timestamp":1735233250358,"user_tz":-300,"elapsed":17,"user":{"displayName":"Abbas Mirza","userId":"04098176250439025995"}},"outputId":"3dc4f29e-a109-4edc-a302-039a6d0a4464"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-25-a2e6e657fa2a>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  loaded_checkpoint = torch.load(\"checkpoint1.pth\")\n"]}]},{"cell_type":"code","source":["epoch = loaded_checkpoint[\"epoch\"]\n","\n","#initializing model and optimizer\n","model = Model(6)\n","optimizer = torch.optim.SGD(model.parameters(), lr=0)\n","\n","model.load_state_dict(loaded_checkpoint[\"model_state\"])\n","optimizer.load_state_dict(loaded_checkpoint[\"optim_state\"])\n","\n","#continue model training..."],"metadata":{"id":"crWxc1P44xvl","executionInfo":{"status":"ok","timestamp":1735233265878,"user_tz":-300,"elapsed":3,"user":{"displayName":"Abbas Mirza","userId":"04098176250439025995"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["print(\"Loaded Optimizer State Dict: \",optimizer.state_dict())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9euTddQ25fAA","executionInfo":{"status":"ok","timestamp":1735233269769,"user_tz":-300,"elapsed":520,"user":{"displayName":"Abbas Mirza","userId":"04098176250439025995"}},"outputId":"37c9b4df-9c5e-4828-9436-e53e1d8ee6dd"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded Optimizer State Dict:  {'state': {}, 'param_groups': [{'lr': 0.01, 'momentum': 0, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'fused': None, 'params': [0, 1]}]}\n"]}]},{"cell_type":"markdown","source":["##Using GPU:"],"metadata":{"id":"QCTgguWU507-"}},{"cell_type":"markdown","source":["###Option 1 - Save on GPU, Load on CPU:"],"metadata":{"id":"VMXGf2497Zkv"}},{"cell_type":"code","source":["#Option 1 - Save on GPU, Load on CPU\n","device = torch.device(\"cuda\")\n","model.to(device)\n","torch.save(model.state_dict(), FILE)"],"metadata":{"id":"0s6myOQH53J-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cpu')\n","model = Model(6)\n","model.load_state_dict(torch.load(FILE, map_location=(device)))"],"metadata":{"id":"SQ9SMF596jsb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Option 2 - Save & Load on GPU"],"metadata":{"id":"35b9sqik7dCl"}},{"cell_type":"code","source":["# Option 2 - Save & Load on GPU\n","device = torch.device(\"cuda\")\n","model.to(device)\n","torch.save(model.state_dict(), FILE)"],"metadata":{"id":"-aDLShvy7HAY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Model(6)\n","model.load_state_dict(torch.load(FILE))\n","model.to(device)"],"metadata":{"id":"VjS0orKo7HAZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Option 3 - Save on CPU, Load on GPU"],"metadata":{"id":"gDw_Ox757fwJ"}},{"cell_type":"code","source":["#Option 3 - Save on GPU, Load on CPU\n","torch.save(model.state_dict(), FILE)"],"metadata":{"id":"vcdkFBnX7PWp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda')\n","model = Model(6)\n","model.load_state_dict(torch.load(FILE, map_location=(\"cuda:0\"))) #choose GPU device number\n","model.to(device)"],"metadata":{"id":"jUTBhnLY7PWq"},"execution_count":null,"outputs":[]}]}